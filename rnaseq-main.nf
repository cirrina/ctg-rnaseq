
// Basics:
// Primer
// driver
// nf main script


// Configuration implicit variables. These are implicitly defined in the Nextflow configuration file
  // baseDir    - projectDir in v20.04.x: The directory where the main workflow script is located
  // workDir    - the work folder for nextflow temporary work-files
  // launchDir  - the directory where the workflow is run (requires version 20.04.0 or later).

  // [nas-sync/upload]: ls4 Illumina runfolder upload sync dir, shared/ctg-projects/nas-sync/upload/
  //    └──– [runfolder] = Illumina runfolder.
  //      |--- Data ....
  //      |
  //      └──-

  // [basedir]: ls4 ctg projets base directory, e.g. shared/ctg-projects/rnaseq
  //   └──–– [projectdir] = workdir = nf execution dir = baseDir. e.g. shared/ctg-projects/rnaseq/<projectid>
  //      |--- [fastq] (if demux)
  //      |      |- <project_id>
  //      |      |      └── fastq-files.fastq.gz
  //      |      |- Reports
  //      |      |- Stats
  //      |      └─ "Undetermined ... fastq.gz ". Remember to NOT COPY these if pooled sample
  //      |---  "nextflow.config"
  //      |---  "ctg-rnaesq.nf"
  //      |---  "sample sheet original IEM"
  //      |---  [nfworkdir] = workDir: shared/ctg-projects/rnaseq/work; used by Nextflow
  //      └──-  [outputdir]: shared/ctg-projects/rnaseq/nf-output







/* ===============================================================
  *      PARAMS FROM CONFIGS
  =============================================================== */

//  project specific config, generated by shell & Rscipt
// ----------------------------------------------------

//  project and run folders
projectid           =  params.projectid    // ctg project id. e.g. 2021_024
projectdir          =  params.projectdir   // .../shared/uroscan/2021_024


// root directories
project_root        =  params.project_root  // project work folder, .../shared/uroscan/
delivery_root       =  params.delivery_root  // final dir for delivery.  Files are moved to here from temp project/nextflow work folder
ctg_save_root       =  params.ctg_save_root  // dir where ctg saves QC, samplesheets logs etc

// n_samples           =  params.n_samples

//  samplesheets
samplesheet_ctg       =  params.samplesheet           // name of simple sample sheet used for pipeline. Must includes file paths to fastq and bamsm, as well as species etc.
samplesheet_demux     =  params.samplesheet_demux     // name of IEM style samplesheet used for bcl2fastq. often generated by iem-samplesheet-processor.R
samplesheet_original  =  params.samplesheet_original  // Name of The original (non-altered) sample sheet as obtained from lab


//  demux specific params
runfolderdir        =  params.runfolderdir        // illumina raw data runfolder (full path)
runfolder           =  params.runfolder           // illumina raw data runfolder (folder name only)
bcl2fastq_dir  =  params.bcl2fastq_dir  // base directry where blc2fastq will write its output to (including undetermined fastq and stats folder).
fastqdir            =  params.fastqdir            // subdirectory where blc2fastq will write fastq files to. fastq-files will be read according to sample sheet. Defaults to <bcl2fastq_dir>/<projectid>
// NOTE: if skip_demux is TRUE, then fastq files must FOR NOW be out in ${projectdir}/nf-output/fastq/{projectid}, i.e. the default location for bcl2fastqc


/* ===============================================================
  *      DEFINE DIRECTORIES FROM PARAMS
  =============================================================== */

outputdir =  projectdir+'/nf-output' // main ooutput directory for files genetated with the Pipeline
file(outputdir).mkdir() // main nexttlow work dir for output of analyses. Subdirectory of the project foilder. Files and folders will be moved and copiued from this folder upon pipeline  completion.

deliverydir  =  delivery_root + '/' + projectid  // final delivery dir (on ... /nas-sync/. Note that delivery is prepared in "deliverytemp" is used in projectfolder)
ctg_save_dir =  ctg_save_root + '/' + projectid



// the deliverytemp will be used to save analyses that are bound for delivery t ocustomer

// output dirs to delivery
deliverytemp  =  outputdir+'/delivery' // this temp deliverydir is used within the nf workfolder/outputdir to store files that are comitted for delivery. A customer multiqc will be run only on this dir. Upon completion of all analyses this will be moved to delivery dir
stardir = deliverytemp+'/star'
salmondir = deliverytemp+'/salmon'
rsemdir = deliverytemp+'/rsem'

bladderreportdir = deliverytemp+'/bladderreport'

deliverysamplesheets = deliverytemp+'/samplesheets'
deliveryscripts = deliverytemp+'/scripts'
deliveryconfigs = deliverytemp+'/configs'
deliverylogs = deliverytemp+'/logs'

deliveryqc = deliverytemp+'/qc'
fastqcdir = deliveryqc+'/fastqc'

multiqcdeliverydir  =  deliveryqc + '/multiqc'
mqcreport = multiqcdeliverydir + '/' + projectid + '_multiqc_report'
readme = deliverydir +'/README_ctg_delivery_' + projectid


// output for qc - temp workdirs
qcdir = outputdir+'/qc'
qualimapdir = qcdir+'/qualimap'
rseqcdir = qcdir+'/rseqc'
featurecountsdir = qcdir+'/featurecounts'

markdupstempdir = qcdir+'/markdups_bam_tmp'
markdupsqcdir = qcdir+'/markdups'
rnaseqmetricsdir = qcdir+'/rnaseqmetrics'
multiqcctgdir = qcdir+'/multiqc-ctg'
fastqscreendir = qcdir+'/fastqscreen'


/// ctg sav dirs
ctg_save_samplesheets = ctg_save_dir+'/samplesheets'
ctg_save_scripts = ctg_save_dir+'/scripts'
ctg_save_configs = ctg_save_dir+'/configs'
ctg_save_logs =  ctg_save_dir+'/logs'


// Illumina runfolder stats
interopdir_ilm = runfolderdir + '/InterOp'
interopdir_ctg = runfolderdir + '/ctg-interop'






/* ===============================================================
  *       create output and logdirs
  =============================================================== */

// log file for nextflow .onComplete
logfile   =  file( projectdir + '/' + 'log.nextflow.complete' )
// logfile_sav          =  file( ctg_save_dir + '/' + 'log.nextflow.complete' )






/* ===============================================================
  *       CHECKS FILES AND PARAMS
  =============================================================== */


//  Check paramters
// -----------------------------
if (projectid         == '') {exit 1, "You must define a project_id in the nextflow.config"}
if (samplesheet_ctg   == '') {exit 1, "You must define a sample sheet path in the nextflow.config"}


// Check if files and directories exist
checkPathParamList = [
  project_root, delivery_root, ctg_save_root,
  projectdir,
  outputdir,
  samplesheet_ctg
]
for (param in checkPathParamList) {
    if (param) {
	file(param, checkIfExists: true)
    }
}

// Demux specific (bcl2fastq2 )
// -----------------------------
// Check if runfolder is defined.
// If not set demux to false and assume that a custom fastq dir is supplied -- not implemented
if ( params.run_blcl2fastq == true ) {
  file(runfolderdir, checkIfExists: true)
  file(samplesheet_demux, checkIfExists: true)
}


// // Debug & test params
// // -----------------------------
debug_mode = false // will turn echo to true



/* ===============================================================
  *       MESSAGES
  =============================================================== */



def msg_deliverymail = """\

  CTG Delivery ${projectid}
  --------------------------

  Hi,

The sequencing, QC and alignment for project project $projectid is now complete. Please find attached multiQC report and CTG delivery report.

The data can be downloaded from our delivery server lfs603.

  Userid:
  Password:

  Total file size:


We avoid sending passwords through mail. Also, we need to activate for your IP address. So please reply to this mail with a phone number to which I can sms text the password and the IP adress of the computer that you will download the data from.

Data is downloaded from our server using SCP (Secure Copy Protocol) protocol. This can be performed either using terminal or using a file transfer software that support SCP file transfers, e.g. FileZilla. Detailed instructions on how to download data, and how to obtain your computer IP adress is depicted in the 'CTG Data Delivery Guide' attached to this mail.

Data will be kept by us for a maximum of 3 months and subsequently deleted. After download, we recommend you to check data integrity using the md5sum-files provided. We strongly recommend you to backup your data, i.e.that have at least two copies. CTG can not help you if your data gets corrupt or lost!

Please do not hesitate to get back to us if you have any questions. Also, please let us know when the data is successfully downloaded.



Kind regards

David Lindgren



 """


// Define messages to print and for logfiles
def msg_startup = """\

    Workflow execution parameters
    ---------------------------------
    project id              :  ${projectid}
    project work dir        :  ${projectdir}
    nextflow execution dir  :  ${baseDir}
    nextflow output dir     :  ${outputdir}
    nextflow work dir       :  ${workDir}
    sample sheet ctg        :  ${samplesheet_ctg}
    sample sheet demux      :  ${samplesheet_demux}
   """
       .stripIndent()
println( msg_startup )



workflow.onComplete {

  def msg_completed = """\

  	Pipeline execution summary
  	---------------------------
  	Completed at : ${workflow.complete}
  	Duration     : ${workflow.duration}
  	Success      : ${workflow.success}
  	scriptFile   : ${workflow.scriptFile}
    exit status  : ${workflow.exitStatus}
  	errorMessage : ${workflow.errorMessage}
  	errorReport  :
  	"""
  	.stripIndent()
  def error = """\
		${workflow.errorReport}
	   """


  // base = csv.getBaseName()
  logfile.text = msg_startup.stripIndent()
  logfile.append( msg_completed.stripIndent() )
  logfile.append( error )

  // if ( new File( logfile ).exists() && ! new File( logfile_sav ).exists())  { new File( logfile_sav ) << new File( logfile ).text }

  println( msg_completed )
}


def msg_modules = """\

    Run modules
    ---------------------------------
    run_blcl2fastq    :  ${params.run_blcl2fastq}
    fastqc        :  ${params.run_fastqc}

   """
   .stripIndent()

println( msg_modules )





// all samplesheet info
// if ( params.paired == true ) {
Channel
  .fromPath(samplesheet_ctg)
  .splitCsv(header:true)
  .map { row -> tuple( row.Sample_ID, row.fastq_1, row.fastq_2, row.Species ) }
  .tap{ infoall }
  .set { fastq_ch }

Channel
  .fromPath(samplesheet_ctg)
  .splitCsv(header:true)
  .map { row -> tuple( row.Sample_ID, row.bam, row.Strandness, row.Species, row.RIN, row.concentration ) }
  .tap { infobam }
  .into { bam_checkbam_ch; bam_indexbam_ch; bam_rnaseqmetrics_ch; bam_markdups_ch; bam_qualimap_ch; bam_rseqc_ch;  bam_bladderreport_ch }

Channel
    .fromPath(samplesheet_ctg)
    .splitCsv(header:true)
    .map { row -> tuple( row.bam ) }
    .tap{ infoallfcounts }
    .set { bam_featurecounts_ch }


println " > Samples to process: "
println "[Sample_ID,fastq1,fastq2,species]"
infoall.subscribe { println "Info: $it" }




/* ===============================================================
  *    ++++ START PROCESSES ++++
  =============================================================== */



/* ===============================================================
  *    --- Demux and fastq files section ---
  =============================================================== */

// Run bcl2fastq
// Channel to start count if demux == 'n'
// if ( params.run_blcl2fastq == false ) {
//    Channel
// 	 .from("x")
//    .set{ fastq_check_ch }
// }
process bcl2fastq {
  // -w must be lower than number of samples
  // publishDir "${fastqdir}", mode: 'copy', overwrite: 'true'
  cpus 4
  tag "$projectid"
  memory '110 GB'
  time '36h'


  input:
  val samplesheet_demux

  output:
  val "x" into bcl2fastq_complete_ch

  // when: params.run_blcl2fastq

  script:
  if ( params.run_blcl2fastq )
  """
  mkdir -p ${bcl2fastq_dir}

  bcl2fastq -R ${runfolderdir} \\
            --sample-sheet ${samplesheet_demux} \\
            --no-lane-splitting  \\
            -r 1 \\
            -p ${task.cpus}  \\
            -w 1  \\
            --output-dir ${bcl2fastq_dir}

  #chmod -R g+rw ${projectdir}
  find ${projectdir} -user $USER -exec chmod g+rw {} +
   """
   else
   """
   echo "skipping  blcl2fastq"
   """
}


/// run_checkfiles_fastq = NOT OPTIONAL !!!

process checkfiles_fastq {
  // Run fastqc. Also check if all expected files, defined in the ctg samplesheet, are present in fastqdir
  tag "$sid"
  cpus 1
  memory '5 GB'
  time '3h'

  input:
  val x from bcl2fastq_complete_ch.collect()
  set sid, read1, read2, species from fastq_ch

  output:
  val "x" into run_star_ch
  val "x" into run_salmon_ch
  val "x" into run_rsem_ch
  set sid, read1, read2, species into fastqc_ch
  set sid, read1, read2, species into star_ch
  set sid, read1, read2, species into salmon_ch
  set sid, read1, read2, species into rsem_ch
  set sid, read1, read2, species into fastqscreen_ch


  script:
  if( params.paired )
    """
      echo "checking fastq files - paired reads "
      if [ ! -f ${fastqdir}/${read1} ]; then
        echo "Warning: Cannot locate fastq_1 file ${fastqdir}/${read1}"
        exit 2
      fi

      if [ ! -f ${fastqdir}/${read1} ]; then
        echo "Warning: Cannot locate fastq_2 file ${fastqdir}/${read2}"
        exit 2
      fi
    """
  else
    """
      echo "checking fastq files - non paired  "

      if [ ! -f ${fastqdir}/${read1} ]; then
        "Cannot locate fastq_1 file ${read2}"
        exit 2
      fi
    """
  // else
  //   """
  //     echo "file check overridden"
  //   """

}




/* ===============================================================
  *      -- ALIGMENT SECTION --
  =============================================================== */

  // Run STAR: ls4 ctg projets base directory, e.g. shared/ctg-projects/rnaseq
  //   └──–– check_bam: uses sample sheet to check if expected bams are generated
  //      |-  index_bam : optional
  //      |-  markdups  : optional
  //      └── rnaseqmetrics : optional
  //   The three latter are always run to generate flag - but may be run with no script if set ti false
  //    When all three are run, process


//
// if ( run_star == false ) {
//   Channel
// 	 .from("x")
//   .into{ align_complete_ch ; align_complete_report_ch}
// }



// Run salmon
// if ( params.run_salmon == false ) {
//    Channel
// 	 .from("x")
//    .set{ salmon_complete_ch }
// }
process salmon  {
  tag "$sid"
  cpus 6
  memory '48 GB'
  time '36h'
  echo debug_mode
  //publishDir "${stardir}", mode: 'copy', overwrite: true

  input:
  val x from run_salmon_ch.collect()
  set sid, read1, read2, species from salmon_ch // from checkfiles_fastq

  output:
  val "x" into salmon_complete_ch

  // when: params.run_salmon

  script:
  if ( species == "Homo sapiens" ){
    transcripts=params.salmon_transcripts_hs }
  else if ( species == "Mus musculus" ){
    transcripts=params.salmon_transcripts_mm  }
  else if ( species == "Rattus norvegicus" ){
    transcripts=params.salmon_transcripts_rn  }
  else{
    genome = ""
    println( "Warning: Species not recognized." )}

  // if ( params.paired )


  if ( params.paired && params.run_salmon )
    """
    salmon quant -l A \\
      -i  ${transcripts} \\
      -1  ${fastqdir}/${read1} \\
      -2  ${fastqdir}/${read2} \\
      -p  6 --validateMappings \\
      -o  ${salmondir}/${sid}_0.salmon.salmon \\
      --no-version-check

    #chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +

    """
  else if ( !params.paired && params.run_salmon )
    """
    salmon quant -l A \\
      -i  ${transcripts} \\
      -1  ${fastqdir}/${read1} \\
      -p  6 --validateMappings \\
      -o  ${salmondir}/${sid}_0.salmon.salmon \\
      --no-version-check

    #hmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "skipping salmon"
    """

}




// Run STAR
// if ( params.run_star == false ) {
//    Channel
// 	 .from("x")
//    .set{ star_complete_ch }
// }
process star  {
  tag "$sid"
  cpus 20
  memory '100 GB'
  time '36h'
  echo debug_mode
  //publishDir "${stardir}", mode: 'copy', overwrite: true

  input:
  val x from run_star_ch.collect()
  set sid, read1, read2, species from star_ch // from checkfiles_fastq

  output:
  val "x" into star_complete_ch

  // when: params.run_star

  script:
  if ( species == "Homo sapiens" ){
    genome=params.star_genome_hs }
  else if ( species == "Mus musculus" ){
    genome=params.star_genome_mm }
  else if ( species == "Rattus norvegicus" ){
      genome=params.star_genome_rn }
  else{
    genome = ""
    println( "Warning: Species not recognized." )}

  if ( params.paired ){
      starfiles = "${fastqdir}/${read1} ${fastqdir}/${read2}" }
  else{
      starfiles = "${fastqdir}/${read1}" }


  if ( params.run_star )
  """
  mkdir -p ${stardir}

  ### added genomeLoad remove - star crashes if not for version 2.5x uroscan pipeline
  STAR  --genomeDir ${genome} --genomeLoad Remove

  STAR --genomeDir ${genome} \\
    --readFilesIn ${starfiles} \\
    --runThreadN ${task.cpus}  \\
    --readFilesCommand zcat \\
    --outSAMtype BAM SortedByCoordinate \\
    --genomeLoad LoadAndKeep \\
    --limitBAMsortRAM 10000000000 \\
    --outFileNamePrefix ${stardir}/${sid}_

  # chmod -R g+rw ${projectdir}
  find ${projectdir} -user $USER -exec chmod g+rw {} +
  """
  else
  """
  echo "skipping star"
  """

}




// Check STAR bam files against names in sample sheet
// checkfiles_star
// Channel to start count if demux == 'n'
// if ( params.run_checkfiles_bam == false ) {
//    Channel
// 	 .from("x")
//    .set{ checkfiles_bam_complete_ch }
// }
process checkfiles_bam {
  // Run fastqc. Also check if all expected files, defined in the ctg samplesheet, are present in fastqdir
  tag "$sid"
  cpus 1
  memory '1 GB'
  time '1h'
  echo debug_mode

  input:
  val x from star_complete_ch.collect() // checkbam_ch - when star is completed
  set sid, bam, strand, species, RIN, concentration from bam_checkbam_ch

  output:
  val "x" into checkfiles_bam_complete_ch

  // when: params.run_checkfiles_bam

  script:
  if( params.run_checkfiles_bam )
    """
      if [ ! -f ${stardir}/${bam} ]; then
        echo "Warning: Cannot locate bam file ${stardir}/${bam}"
        exit 2
      fi
    """
  else
    """
    echo "file check overridden"
  """
}



// RSEM
// if ( params.run_rsem == false ) {
//    Channel
// 	 .from("x")
//    .set{ rsem_complete_ch }
// }

process rsem {
  tag "$sid"
  cpus 20
  memory '100 GB'
  time '36h'
  //publishDir "${stardir}", mode: 'copy', overwrite: true

  input:
  val x from run_rsem_ch.collect()
  set sid, read1, read2, species from rsem_ch // from checkfiles_fastq

  output:
  val "x" into rsem_complete_ch
  val "x" into rsem_complete_report_ch
  // file "${sid}_Aligned.sortedByCoord.out.bam" into bam_featurecounts_ch // channel defined start instead

  script:

  // species and references (bowtie2 refs)
  if ( species == "Homo sapiens" ){
    genome=params.rsem_bowtie2_genome_hs }
  else if ( species == "Mus musculus" ){
    genome=params.star_genome_mm }
  else if ( species == "Rattus norvegicus" ){
      genome=params.star_genome_rn }
  else{
    genome = ""
    println( "Warning: Species not recognized." )
  }

  // paired end
  if ( params.paired ){
    rsemfiles = "${fastqdir}/${read1} ${fastqdir}/${read2}"
    paired='--paired-end'}
  else{
    rsemfiles = "${fastqdir}/${read1}"
    paired=''}

  // strand
  if( params.strandness == "forward" )
    strand = 'forward'
  else if ( params.strandness == "reverse" )
    strand = 'reverse'
  else
    strand = 'none'



    //the uroscan pipe is run without strandness flag.
  if ( params.run_rsem && params.pipelineProfile == "uroscan" )
    """
    mkdir -p ${rsemdir}
    rsem-calculate-expression \\
        --num-threads ${task.cpus} \\
        --paired-end \\
        --bowtie2 \\
        --bowtie2-path /opt/software/uroscan_env/bin \\
        --estimate-rspd \\
        --append-names \\
        --no-bam-output \\
        ${rsemfiles} \\
        ${genome} \\
        ${rsemdir}/${sid}.rsem

    #chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else if ( params.run_rsem && params.pipelineProfile == "uroscan" )
    """
    mkdir -p ${rsemdir}
    rsem-calculate-expression \\
        --num-threads ${task.cpus} \\
        ${paired} \\
        --strandedness ${strand} \\
        --bowtie2 \\
        --bowtie2-path /opt/software/uroscan_env/bin \\
        --estimate-rspd \\
        --append-names \\
        --no-bam-output \\
        ${rsemfiles} \\
        ${genome} \\
        ${rsemdir}/${sid}.rsem

    find ${projectdir} -user $USER -exec chmod g+rw {} +
    #chmod -R g+rw ${projectdir}
    """
  else
    """
    echo "rsem not run"
    """
}




// Picard rnaesqmetrixcs
// if ( params.run_rnaseqmetrics == false ) {
//    Channel
// 	 .from("x")
//    .set{ rnaseqmetrics_complete_ch }
// }

process rnaseqmetrics {
  tag "$sid"
  cpus 6
  memory '36 GB'
  time '24h'
  echo debug_mode

  input:
  val x from checkfiles_bam_complete_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_rnaseqmetrics_ch

  output:
  val "x" into rnaseqmetrics_complete_ch

  // when: params.run_rnaseqmetrics

  script:
  // NONE, FIRST_READ_TRANSCRIPTION_STRAND, and SECOND_READ_TRANSCRIPTION_STRAND.
  if ( strand == "forward" )
    strand="FIRST_READ_TRANSCRIPTION_STRAND"
  else if ( strand == "reverse" )
    strand="SECOND_READ_TRANSCRIPTION_STRAND"
  else
    strand="NONE"


  if ( species == "Homo sapiens" ){
    refflat = params.picard_refflat_hs
    rrna = params.picard_rrna_hs}
  else if ( species == "Mus musculus" ){
    refflat = params.picard_refflat_mm
    rrna = params.picard_rrna_mm }
  else if ( species == "Rattus norvegicus" ){
      refflat = params.picard_refflat_rn
      rrna = params.picard_rrna_rn }
  else{
    refflat = ""
    rrna = ""
  }

  // if ( params.run_rnaseqmetrics && species == "Rattus norvegicus" )
  // else if ( pecies == "Rattus norvegicus" )
  // changed to NOT use the rrna file. not working anyway?
  if ( params.run_rnaseqmetrics && params.pipelineProfile == "uroscan")
    """
    echo "strand: ${strand}"
    echo "refflat file: ${refflat}"
    mkdir -p ${rnaseqmetricsdir}

    ## java -jar picard.jar CollectRnaSeqMetrics \\ ## old line
    picard CollectRnaSeqMetrics \\
        INPUT=${stardir}/${bam} \\
        OUTPUT=${rnaseqmetricsdir}/${sid}_bam.collectRNAseq.metrics.txt \\
        REF_FLAT=${refflat} \\
        STRAND=${strand}

    find ${projectdir} -user $USER -exec chmod g+rw {} +
    # chmod -R g+rw ${projectdir}

    """
  else if ( params.run_rnaseqmetrics && species == "Rattus norvegicus")
    """
    echo "strand: ${strand}"
    echo "refflat file: ${refflat}"
    mkdir -p ${rnaseqmetricsdir}

    ## java -jar picard.jar CollectRnaSeqMetrics \\ ## old line
    picard CollectRnaSeqMetrics \\
        INPUT=${stardir}/${bam} \\
        OUTPUT=${rnaseqmetricsdir}/${sid}_bam.collectRNAseq.metrics.txt \\
        REF_FLAT=${refflat} \\
        STRAND=${strand}

    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else if ( params.run_rnaseqmetrics && params.pipelineProfile == "rnaseq")
    """
    echo "strand: ${strand}"
    echo "rrna file: ${rrna}"
    echo "refflat file: ${refflat}"
    mkdir -p ${rnaseqmetricsdir}

    picard CollectRnaSeqMetrics \\
      INPUT=${stardir}/${bam} \\
      OUTPUT=${rnaseqmetricsdir}/${sid}_bam.collectRNAseq.metrics.txt \\
      REF_FLAT=${refflat} \\
      STRAND=${strand} \\
      RIBOSOMAL_INTERVALS=${rrna}

    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  // temp workaround - ribosomal intervals file for Rat is not workling in v1.0

  else
    """
    echo "picard rnaseqmetrics skipped"
    """

}




process featurecounts {
  tag "$projectid"
  cpus 20
  memory '350 GB'
  time '96h'

	input:
  val x from rnaseqmetrics_complete_ch.collect()
	val bams from bam_featurecounts_ch.collect()

  output:
	val "x" into featurecounts_complete_ch


  script:
  if( params.strandness == "forward" )
    strand_numeric = 1
  else if ( params.strandness == "reverse" )
    strand_numeric = 2
  else
    strand_numeric = 0

  // gtf used for featurecounts
  if ( params.species_global == "Homo sapiens" ){
    gtf = params.gtf_hs}
  else if  ( params.species_global == "Mus musculus" ){
    gtf = params.gtf_mm}
  else if  ( params.species_global == "Rattus norvegicus" ){
      gtf = params.gtf_rn}
  else{
    gtf=""}

  if( params.run_featurecounts )
    """
    mkdir -p ${featurecountsdir}
    cd ${stardir}
    bamstring=\$(echo $bams | sed 's/,/ /g' | sed 's/\\[//g' | sed 's/\\]//g' )
    echo \${bamstring}

    echo "gtf: ${gtf}"
    featureCounts -T ${task.cpus} \\
      -t ${params.fcounts_feature} \\
      --extraAttributes gene_name,gene_type \\
      -a ${gtf} -g gene_id  \\
      -o ${featurecountsdir}/${projectid}_geneid.featureCounts.txt \\
      -p \\
      -s ${strand_numeric} \${bamstring}

    # chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "featurecounts skipped"
    """
}


/// INDEX BAMs


// samtools index bamfile
// ml Java; ml nextflow/19.04.1
// ml Singularity
// ml GCC/7.3.0-2.30
// ml SAMtools/1.9
// samtools index bamfile

//
// if ( params.run_index_bam == false ) {
//    Channel
// 	 .from("x")
//    .set{ indexbam_complete_ch }
// }

process index_bam {
  tag "$sid"
  cpus 4
  memory '32 GB'
  time '3h'

  input:
  val x from featurecounts_complete_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_indexbam_ch

  output:
  val "x" into indexbam_complete_ch

  // when: params.run_index_bam

  script:
  if ( params.run_index_bam )
    """
    cd ${stardir}
    echo "${stardir}/${bam}"
    # samtools index -bc ${stardir}/${bam}
    sambamba index ${stardir}/${bam}

    """
  else
    """
    echo "skipped indexing"
    """
}


// QUALIMAP
// if ( params.run_qualimap == false ) {
//    Channel
// 	 .from("x")
//    .set{ qualimap_complete_ch }
// }
process qualimap {
  tag "$sid"
  cpus 6
  memory '100 GB'
  time '3h'

  input:
  val x from indexbam_complete_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_qualimap_ch

  output:
  val "x" into qualimap_complete_ch

  // when: params.run_qualimap

  script:
  // gtf used for featurecounts
  if ( params.species_global == "Homo sapiens" ){
    gtf = params.gtf_hs}
  else if  ( params.species_global == "Mus musculus" ){
    gtf = params.gtf_mm}
  else if  ( params.species_global == "Rattus norvegicus" ){
      gtf = params.gtf_rn}
  else{
    gtf=""}

  if ( params.run_qualimap )
    """
    mkdir -p ${qualimapdir}

    ## export JAVA_OPTS="-Djava.io.tmpdir=/data/tmp"
    ## /data/bnf/sw/qualimap_v2.2.1/qualimap --java-mem-size=12G rnaseq -bam /data/bnf/bam/rnaseq/21KF00020.STAR.sort.bam -gtf /data/bnf/ref/rsem/GRCh37/Homo_sapiens.GRCh37.75.gtf -pe -outdir /data/bnf/postmap/rnaseq/21KF00020.STAR.qualimap.folder
    # qualimap --java-mem-size=12G rnaseq -bam /projects/fs1/shared/ctg-projects/uroscan/2021_024/nf-output/delivery/star/21KF00082_Aligned.sortedByCoord.out.bam -gtf /projects/fs1/shared/uroscan/references/rsem/GRCh37/Homo_sapiens.GRCh37.75.gtf -pe -outdir /projects/fs1/shared/ctg-projects/uroscan/2021_024/nf-output/delivery/qualimap/21KF00082.STAR.qualimap.folder

    qualimap --java-mem-size=90G rnaseq -bam ${stardir}/${bam} -gtf ${gtf} -pe -outdir ${qualimapdir}/${sid}.STAR.qualimap.folder

    """
  else
    """
    echo "qualimap skipped"
    """
}


// RSEQC
// if ( params.run_rseqc == false ) {
//    Channel
// 	 .from("x")
//    .set{ rseqc_complete_ch }
// }
process rseqc {
  tag "$sid"
  cpus 6
  memory '32 GB'
  time '3h'

  input:
  val x from qualimap_complete_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_rseqc_ch

  output:
  val "x" into rseqc_complete_ch

  // when: params.run_rseqc

  script:
  if ( params.run_rseqc )
    """
    mkdir -p ${rseqcdir}

    geneBody_coverage.py \\
      -i ${stardir}/${bam} \\
      -r /projects/fs1/shared/uroscan/references/rseqc/hg19.HouseKeepingGenes.bed \\
      -o ${rseqcdir}/${sid}.genebodycov

    #chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "skipped rseeqc"
    """
}




// picard mark duplicates
// if ( params.run_markdups == false ) {
//    Channel
// 	 .from("x")
//    .set{ markdups_complete_ch }
// }
process markdups {
  tag "$sid"
  cpus 6
  memory '32 GB'
  time '24h'

  input:
  //val x from markdups_ch.collect()
  val x from rseqc_complete_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_markdups_ch

  output:
  val "x" into markdups_complete_ch
  val "x" into markdups_complete_report_ch
  // val "x" into move

  // when: params.run_markdups

  script:
  if ( params.run_markdups )
    """
    echo "bam: ${bam}"
    mkdir -p ${markdupstempdir}
    mkdir -p ${markdupsqcdir}

    echo "markdupstempdir: ${markdupstempdir}/${bam}"
    # java -jar picard MarkDuplicates \\
    picard MarkDuplicates \\
        INPUT=${stardir}/${bam} \\
        OUTPUT=${markdupstempdir}/${bam} \\
        METRICS_FILE=${markdupsqcdir}/${sid}_bam.MarkDuplicates.metrics.txt \\
        TAGGING_POLICY=All \\
        REMOVE_DUPLICATES=false \\
        ASSUME_SORTED=true \\
        MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=2000 \\
        QUIET=true \\
        VERBOSITY=WARNING

    mv -f ${markdupstempdir}/${bam} ${stardir}/${bam}

    #chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "run markdups skipped"
    """
}





/* ===============================================================
  *      FASTQSCREEN
  =============================================================== */

// fastq_screen
// if ( params.run_fastqscreen == false ) {
//    Channel
// 	 .from("x")
//    .set{ fastqscreen_complete_ch }
// }
process fastqscreen {
    tag "$sid"
    cpus 16
    memory '32 GB'
    time '24h'

    input:
    set sid, read1, read2, species from fastqscreen_ch //

    output:
    val "x" into fastqscreen_complete_ch

    script:
    if ( params.paired ){
        fqsfiles = "${fastqdir}/${read1} ${fastqdir}/${read2}" }
    else{
        fqsfiles = "${fastqdir}/${read1}" }

    if ( params.run_fastqscreen)
      """
      mkdir -p ${fastqscreendir}

      fastq_screen \\
          --conf ${params.fastqscreen_config} \\
          --subset 500000 \\
          --outdir ${fastqscreendir} \\
          ${fqsfiles}


      """
    else
      """
      echo "run_fastqscreen skipped"
      """
}





/* ===============================================================
  *      FASTQC
  =============================================================== */

process fastqc {
  // Run fastqc. Also check if all expected files, defined in the ctg samplesheet, are present in fastqdir
  tag "$sid"
  cpus 6
  memory '32 GB'
  time '3h'
  // echo true

  input:
  set sid, read1, read2, species from fastqc_ch  // from check fastq

  output:
  val "x" into fastqc_complete_ch

  // when: params.run_fastqc

  script:
  if ( params.paired && params.run_fastqc)
    """
      mkdir -p ${fastqcdir}
      echo "running fastqc in paired reads mode"
      fastqc ${fastqdir}/${read1} ${fastqdir}/${read2}  --outdir ${fastqcdir}
      # chmod -R g+rw ${projectdir}
      find ${projectdir} -user $USER -exec chmod g+rw {} +

  """
  else if ( !params.paired && params.run_fastqc)
    """
      mkdir -p ${fastqcdir}
      echo "running fastqc in non paired reads mode "
      fastqc ${fastqdir}/${read1}  --outdir ${fastqcdir}
      #chmod -R g+rw ${projectdir}
      find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "run_fastqc skipped"
    """
}




/* ===============================================================
  *      BLADDER REPORT
  =============================================================== */

// /usr/bin/Rscript -e "library(rmarkdown, lib='/home/petter/R/x86_64-pc-linux-gnu-library/3.4'); rmarkdown::render('/data/bnf/scripts/bladderreport/bladderreport_ctg_anonymous.Rmd',params=list(sampleid='21KF00020', rsem_in='/data/bnf/premap/rnaseq/21KF00020_0.rsem',star_qc='/data/bnf/tmp/rnaseq/21KF00020_0.sort.bam.folder/Log.final.out', clarity_id='ALL557A36'),output_file='/data/bnf/postmap/rnaseq/21KF00020.STAR.bladderreport_anonymous.html')"


//
// if ( params.run_bladderreport == false ) {
//    Channel
// 	 .from("x")
//    .set{ bladderreport_complete_ch }
// }
process bladderreport {
  tag "$sid"
  cpus 4
  memory '32 GB'
  time '3h'
  echo debug_mode

  input:
  val x from markdups_complete_report_ch.collect()
  val x from rsem_complete_report_ch.collect()
  set sid, bam, strand, species, RIN, concentration from bam_bladderreport_ch

  output:
  val "x" into bladderreport_complete_ch

  // when: params.run_bladderreport

  script:
  bladderreport_scriptsdir = projectdir+'/bin/bladderreport'
  bladderreport_scriptname= params.bladderreport_scriptname


  if ( params.run_bladderreport )
  """
    mkdir -p ${bladderreportdir}/tmp_${sid}
    cp -r ${bladderreport_scriptsdir} ${bladderreportdir}/tmp_${sid}/
    cd ${bladderreportdir}/tmp_${sid}/bladderreport

    Rscript -e "library('rmarkdown'); \\
      rmarkdown::render( \\
        '${bladderreportdir}/tmp_${sid}/bladderreport/${bladderreport_scriptname}',  \\
        params = list(   \\
          sampleid='${sid}', \\
          rsem_in='${rsemdir}/${sid}.rsem.genes.results', \\
          star_qc='${stardir}/${sid}_Log.final.out', \\
          RIN='${RIN}', \\
          concentration='${concentration}'),  \\
        output_file='${bladderreportdir}/${sid}.STAR.bladderreport_anonymous.html')"

    cd ${bladderreportdir}
    # chromium-browser --headless --disable-gpu --no-sandbox --print-to-pdf=${sid}.STAR.bladderreport.pdf ${bladderreportdir}/${sid}.STAR.bladderreport_anonymous.html
    chromium --headless --disable-gpu --no-sandbox --print-to-pdf=${sid}.STAR.bladderreport.pdf ${bladderreportdir}/${sid}.STAR.bladderreport_anonymous.html

    # ${bladderreportdir}/tmp_${sid}/bladderreport/bladder_noreport2txt.pl ${bladderreportdir}/${sid}.STAR.bladderreport_anonymous.html > ${bladderreportdir}/${sid}.STAR.bladderreport_anonymous.txt

    mv ${bladderreportdir}/tmp_${sid}/bladderreport/${sid}.LundClassifier.rds ${bladderreportdir}/${sid}.LundClassifier.rds

    # rm -rf ${bladderreportdir}/tmp_${sid} ## bugs out. move to further down

    #chmod -R g+rw ${projectdir}
    find ${projectdir} -user $USER -exec chmod g+rw {} +

  """
  else
    """
    echo "run_bladderreport skipped"
    """
}










/* ===============================================================
* ===============================================================
  *     ----------- POST ANALYSIS SECTION -------
  ===============================================================
  =============================================================== */





/* ===============================================================
  *     ctg multiqc - on all analyses - runfolder included
  =============================================================== */
// This multiQC is for CTG infouse and not to the customer.
// The customer will obtain a lighter multiQC carried out below


process multiqc_ctg {
  //publishDir "${multiqcctgdir}", mode: 'copy', overwrite: 'true'
  tag "$projectid"
  cpus 8
  memory '64 GB'
  time '3h'
  echo debug_mode

  input:
  val x from fastqc_complete_ch.collect()
  val x from markdups_complete_ch.collect()
  val x from fastqscreen_complete_ch.collect()
  val x from rsem_complete_ch.collect()
  val x from bladderreport_complete_ch.collect()
  val x from salmon_complete_ch.collect()

  output:
  val "x" into multiqc_ctg_complete_ch
  val "x" into multiqc_ctg_complete_2_ch

  // when: params.run_multiqc_ctg

  script:
  if ( params.run_multiqc_ctg )
    """
      mkdir -p ${multiqcctgdir}
      cd ${outputdir}
      multiqc -n ${projectid}_multiqc_report \\
        --interactive \\
        -o ${multiqcctgdir} . ${runfolderdir}

      # chmod -R g+rw ${projectdir}
      find ${projectdir} -user $USER -exec chmod g+rw {} +
    """
  else
    """
    echo "run_multiqc_ctg skipped"
    """
}




/* ===============================================================
  *     Genaerate Delivery folder (temp folder within project dir)
  =============================================================== */
// generate a delivery folder and collect all files n folders to deliver
// run additional multiqc and md5 summ
// This temp delivery folder can be moved to delivery site on ls4 (nas sync) after nextflow sctipt completion.
// this delivery in additional shell script.
// move fastq files to delivery folder
// if not pooled, deliver the complete bcl2fastq directory including stats and undetermined fastq

// setup a deliveryfolder in nextflow dir.
// This will later be moved to /nas-sync/ctg-delivery
// if ( params.run_setup_deliverytemp == false ) {
//    Channel
// 	 .from("x")
//    .set{ setup_deliverytemp_complete_ch }
// }




process stage_delivery {
  cpus 4
  tag "$projectid"
  memory '64 GB'
  time '3h'

  input:
  val x from multiqc_ctg_complete_2_ch.collect()

  output:
  val "x" into stage_delivery_complete_ch

  // when: params.run_setup_deliverytemp

  // add scripts
  // add sample sheets
  // move fastq

  script:
  if ( params.run_stage_delivery )
    """
    ## additional cleanups (star and bladderreport)
    ## -------------------
    if [ -d ${bladderreportdir} ]; then
      cd ${bladderreportdir}
      find . -type d -name "tmp_*" -exec rm -r {} +
    fi

    if [ -d ${stardir} ]; then
      cd ${stardir}
      find . -type d -name "*__STARtmp" -exec rm -r {} +
    fi

    if [ -d ${markdupstempdir} ]; then
      rm -rf ${markdupstempdir}
    fi


    ##  sample sheets
    ## -----------------
    mkdir -p ${deliverysamplesheets}

    if [ -f ${samplesheet_ctg} ]; then
      cp ${samplesheet_ctg} ${deliverysamplesheets}/
    fi
    if [[ -f ${samplesheet_demux} ]]; then
      cp ${samplesheet_demux} ${deliverysamplesheets}/
    fi
    if [ -f ${samplesheet_original} ]; then
      cp ${samplesheet_original} ${deliverysamplesheets}/
    fi


    ##  logs
    ##   -----------------
    ## mkdir -p ${deliverylogs}


    ## scripts dir (executables bins etc, version specific) and configs (project specific)
    ##   --------------------------------------------------------------
    mkdir -p ${deliveryscripts}

    if [[ -d "${params.scriptsdir}" ]]; then
      cp -r ${params.scriptsdir} ${deliveryscripts}
    fi


    ## configs (project specific) as well as the rscript log config
    ##   --------------------------------------------------------------
    mkdir -p ${deliveryconfigs}
    if [[ -f "${projectdir}/nextflow.config.project.${projectid}" ]]; then
      cp ${projectdir}/nextflow.config.project.${projectid} ${deliveryconfigs}
    fi

    if [[ -f "${projectdir}/nextflow.config" ]]; then
      cp ${projectdir}/nextflow.config ${deliveryconfigs}
    fi
    if [[ -f "${runfolderdir}/log.rscript.samplesheet" ]]; then
      cp ${runfolderdir}/log.rscript.samplesheet ${deliveryconfigs}
    fi


    ##  Move delivery temp dir from project folder to delivery location
    ##   --------------------------------------------------------------
    mkdir -p ${deliverydir}
    mv ${deliverytemp}/* ${deliverydir}




    ## chmods
    ## --------
    # chmod -R g+rw
    find ${deliverydir} -user $USER -exec chmod g+rw {} +


    """
  else
    """
    echo "run_setup_deliverytemp skipped"
    """


}

// move fastq files to delivery temp
// -----------------------------
process move_fastq {

  cpus 6
  tag "$projectid"
  memory '64 GB'
  time '3h'
  echo debug_mode

  input:
  val x from stage_delivery_complete_ch.collect()

  output:
  val "x" into move_fastq_complete_ch
  val "x" into move_fastq_complete_2_ch

  script:
    if ( params.pooled_run &&  params.run_move_fastq)
      """
        mkdir -p ${deliverydir}/fastq
        if [ -d ${fastqdir} ]; then
          echo "pooled run. moving fastq foldler only."
          mv -f ${fastqdir} ${deliverydir}/fastq
        fi
      """
    else if ( !params.pooled_run &&  params.run_move_fastq )
      """
      if [ -d ${bcl2fastq_dir} ]; then
        echo "non pooled data. moving comlplete bcl2fastq output foldler."
        mv -f ${bcl2fastq_dir} ${deliverydir}
      elif [ -d ${fastqdir} ]; then
        echo "non pooled run but cannot locate bcl2fastq_dir. moving fastq foldler only."
        mkdir -p ${deliverydir}/fastq
        mv -f ${fastqdir} ${deliverydir}/fastq
      fi
      """
    else
     """
     echo "run_move_fastq skipped"
     """
}



// Run customer multiQC (on delivery temp folder only).
// -----------------------------
// Not to be confused with ctg-multiqc that is run on all analyses and runfolder

// if ( params.run_multiqc_delivery == false ) {
//    Channel
// 	 .from("x")
//    .set{ multiqc_complete_ch }
// }
process multiqc_delivery {

  tag "$projectid"
  cpus 6
  memory '32 GB'
  time '3h'
  echo debug_mode

  input:
  val x from move_fastq_complete_ch.collect()

  output:
  val "x" into multiqc_complete_ch

  // when: params.run_multiqc_delivery

  script:
  // if (! new File( mqcreport+'.html' ).exists() && params.run_multiqc_delivery)
 if ( params.run_multiqc_delivery )
  """
    ## remove if multiqc is already present from failed run. Will not overwrite ...
    rm -rf ${multiqcdeliverydir}
    mkdir -p ${multiqcdeliverydir}
    cd ${deliverydir}
    multiqc -n ${mqcreport} \\
      --interactive \\
      -o ${multiqcdeliverydir} .
  """
  else
  """
    echo "skipping run_multiqc_delivery"
  """

}


//    md5 sum on deliverydir
// -----------------------------
// generate md5 sum on all files included in delivery temp folder
// if ( params.run_md5sum_delivery == false ) {
//    Channel
// 	 .from("x")
//    .set{ md5sum_complete_ch }
// }
process md5sum_delivery {
  cpus 8
  tag "$projectid"
  memory '64 GB'
  time '3h'

  input:
  val x from multiqc_complete_ch.collect()

  output:
  val "x" into md5sum_complete_ch

  // when: params.run_md5sum_delivery

  script:
  md5sumfile = deliverydir + '/md5sum.txt'

  // if (! new File( md5sumfile ).exists() && params.run_md5sum_delivery)
  if ( params.run_md5sum_delivery )
  """
   cd ${deliverydir}
   find . -type f -exec md5sum {} \\; > ${md5sumfile} ; echo
  """
  else
  """
  echo "skipping run_md5sum_delivery"
  """
  // else
  //   """
  //     echo "${md5sumfile} already exists. skipping."
  //   """
}





/* ===============================================================
  *     FINALIZE CTG SAVE & MOVE DELIVERY - save qc files and scripts
  =============================================================== */
// CTG should store multiQC (ctg-multiqc) and fastqc for all samples
// as of this version files are copied to ctg-qc dir. could change to the folder that also keep scripts and configs and sample sheets
// save

//  - multiQC (ctg_multiqc)
//  - fastQC
//
//  - Sample Sheets in ./samplesheets/
//  - Nextflow scripts, nextflow.config.project., rnaseq-main, nextflow.config, drivers, ./bin files etc (./scripts)

//  - logs,  (the final nextflow genereated onComplee is copied in that segion)
// if ( params.run_stage_ctg_save == false ) {
//    Channel
// 	 .from("x")
//    .set{ stage_ctg_save_complete_ch }
// }
process stage_ctg_save {
  cpus 4
  tag "$projectid"
  memory '32 GB'
  time '3h'

  input:
  val x from multiqc_ctg_complete_ch.collect()
  val x from move_fastq_complete_2_ch.collect()

  output:
  val "x" into stage_ctg_save_complete_ch

  // when: params.run_stage_ctg_save


  script:
  if (params.run_stage_ctg_save)
  """

  ##  sample sheets
  ## -----------------
  cd ${projectdir}

  mkdir -p ${ctg_save_samplesheets}

  if [ -f ${samplesheet_ctg} ]; then
    cp ${samplesheet_ctg} ${ctg_save_samplesheets}
  fi
  if [[ -f ${samplesheet_demux} ]]; then
    cp ${samplesheet_demux} ${ctg_save_samplesheets}
  fi
  if [ -f ${samplesheet_original} ]; then
    cp ${samplesheet_original} ${ctg_save_samplesheets}
  fi


  ##  logs
  ##   -----------------
  mkdir -p ${ctg_save_logs}


  ## scripts dir (executables bins etc, version specific) and configs (project specific)
  ##   --------------------------------------------------------------
  mkdir -p ${ctg_save_scripts}

  if [[ -d "${params.scriptsdir}" ]]; then
    cp -r ${params.scriptsdir} ${ctg_save_scripts}
  fi


  ## configs (project specific) as well as the rscript log config
  ##   --------------------------------------------------------------
  mkdir -p ${ctg_save_configs}
  if [[ -f "${projectdir}/nextflow.config.project.${projectid}" ]]; then
    cp ${projectdir}/nextflow.config.project.${projectid} ${ctg_save_configs}
  fi

  if [[ -f "${projectdir}/nextflow.config" ]]; then
    cp ${projectdir}/nextflow.config ${ctg_save_configs}
  fi
  if [[ -f "${runfolderdir}/log.rscript.samplesheet" ]]; then
    cp ${runfolderdir}/log.rscript.samplesheet ${ctg_save_configs}
  fi


  ##  duplicate the fastqc analyses from delivery dir
  ## -----------------------------------------
  cp -r ${deliverydir}/fastqc ${qcdir}


  ##  Move ctg qc dir from project folder to delivery location
  ##   --------------------------------------------------------------
  mv ${qcdir} ${ctg_save_dir}

  # chmod -R g+rw ${ctg_save_dir}
  find ${ctg_save_dir} -user $USER -exec chmod g+rw {} +

  """
  else
  """
    echo "skipping run_stage_ctg_save"
  """
}



//
// process checkfiles_rscript_predelivery {
//   cpus 4
//   tag "$projectid"
//   memory '32 GB'
//   time '3h'
//
//   input:
//   val x from stage_ctg_save_complete_ch.collect()
//
//   output:
//   val "x" into checkfiles_rscript_predelivery_ch
//
//   // when: params.run_checkfiles_rscript_predelivery
//
//   script:
//   if( params.run_checkfiles_rscript_predelivery)
//   """
//     ## first check output files using rscript. Then move delivery files
//     ${projectdir}/bin/samplecheck.R \\
//       --sample_sheet ${samplesheet_ctg} \\
//       --project_id ${projectid} \\
//       --check_dir ${projectdir}
//       --output ${deliverydir}/log.rscript.filecheck.csv
//
//   """
//   else
//   """
//     echo "skipping run_checkfiles_rscript_predelivery"
//   """
//
// }


// Finalize deliverydir
// -----------------------------
// provess add README with dir size


process finalize_pipeline {
  cpus 2
  tag "$projectid"
  memory '16 GB'
  time '3h'

  input:
  val x from md5sum_complete_ch.collect()
  val x from stage_ctg_save_complete_ch.collect()

  //val x from checkfiles_rscript_predelivery_ch.collect()

  output:
  val "x" into finalize_pipeline_ch



  script:
  if (params.run_finalize_pipeline)
  """
    cd ${deliverydir}


    echo "ctg delivery complete"               > $readme
    echo "Project:   ${projectid}"             >> $readme
    du -ch -d 0 . | grep 'total'               >> $readme

    #chmod -R g+rw ${deliverydir}
    #chmod -R g+rw ${projectdir}
    #chmod -R g+rw ${ctg_save_dir}
    find ${deliverydir} -user $USER -exec chmod g+rw {} +
    find ${projectdir} -user $USER -exec chmod g+rw {} +
    find ${ctg_save_dir} -user $USER -exec chmod g+rw {} +


  """
  else
  """
    echo "skipping run_finalize_pipeline"
  """
}



// process checkfiles_rscript_postdelivery {
//
//   cpus 4
//   tag "$projectid"
//   memory '32 GB'
//   time '3h'
//
//   input:
//   val x from finalize_pipeline_ch.collect()
//
//   output:
//   val "x" into checkfiles_rscript_postdelivery_ch
//
//   // when: params.checkfiles_rscript_postdelivery_ch
//
//   script:
//   if( params.run_checkfiles_rscript_postdelivery)
//   """
//     cd ${deliverydir}
//
//     ## check output files using rscript
//     ${projectdir}/bin/samplecheck.R \\
//       --sample_sheet ${samplesheet_ctg} \\
//       --project_id ${projectid} \\
//       --check_dir ${ctg_save_dir}
//       --output ${ctg_save_dir}/log.rscript.filecheck.csv
//
//     cd ${ctg_save_dir}
//
//       ## check output files using rscript
//       ${projectdir}/bin/samplecheck.R \\
//         --sample_sheet ${samplesheet_ctg} \\
//         --project_id ${projectid} \\
//         --check_dir ${deliverydir}
//         --output ${deliverydir}/log.rscript.filecheck.csv
//
//   """
//   else
//   """
//     echo "skipping checkfiles_rscript_postdelivery"
//   """
// }
